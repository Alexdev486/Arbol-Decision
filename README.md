# ğŸŒ³ Ãrbol de DecisiÃ³n - PredicciÃ³n de Medicamentos

AnÃ¡lisis completo y profesional de un **Ãrbol de DecisiÃ³n** usando el dataset de Kaggle: **pablomgomez21/drugs-a-b-c-x-y-for-decision-trees**

## ğŸ“‹ DescripciÃ³n

Este proyecto implementa un modelo de clasificaciÃ³n basado en **Decision Tree** para predecir quÃ© medicamento (A, B, C, X, o Y) debe prescribirse a un paciente basÃ¡ndose en caracterÃ­sticas como:
- Edad
- GÃ©nero  
- PresiÃ³n arterial
- Colesterol
- Ãndice de sodio/potasio en sangre

## ğŸ¯ Objetivos

- âœ… ExploraciÃ³n y anÃ¡lisis de datos (EDA)
- âœ… Preprocesamiento y codificaciÃ³n de variables
- âœ… ConstrucciÃ³n de modelo base y optimizado
- âœ… OptimizaciÃ³n de hiperparÃ¡metros con GridSearchCV
- âœ… ValidaciÃ³n cruzada (5-fold)
- âœ… EvaluaciÃ³n detallada con mÃºltiples mÃ©tricas
- âœ… VisualizaciÃ³n de resultados
- âœ… ExtracciÃ³n de reglas del Ã¡rbol

## ğŸ“ Estructura del Proyecto

```
Arbol-Decision/
â”œâ”€â”€ Arbol_de_Decision.ipynb    # Notebook principal con anÃ¡lisis completo
â”œâ”€â”€ requirements.txt            # Dependencias del proyecto
â”œâ”€â”€ kaggle.json                 # Credenciales de Kaggle (no incluido)
â”œâ”€â”€ README.md                   # Este archivo
â””â”€â”€ LICENSE                     # Licencia del proyecto
```

## ğŸš€ InstalaciÃ³n y ConfiguraciÃ³n

### 1. Clonar el repositorio
```bash
git clone https://github.com/tu-usuario/Arbol-Decision.git
cd Arbol-Decision
```

### 2. Instalar dependencias
```bash
pip install -r requirements.txt
```

### 3. Configurar Kaggle

1. Ve a tu cuenta de Kaggle â†’ Settings â†’ API â†’ "Create New API Token"
2. Descarga el archivo `kaggle.json`
3. Coloca `kaggle.json` en el directorio raÃ­z del proyecto

### 4. Ejecutar el notebook

```bash
jupyter notebook Arbol_de_Decision.ipynb
```

El notebook descargarÃ¡ automÃ¡ticamente el dataset y ejecutarÃ¡ todo el anÃ¡lisis.

## ğŸ“š Contenido del Notebook

El notebook estÃ¡ organizado en **16 secciones didÃ¡cticas**:

1. **IntroducciÃ³n** - Â¿QuÃ© es un Ãrbol de DecisiÃ³n?
2. **ImportaciÃ³n de LibrerÃ­as** - Herramientas necesarias
3. **Descarga y Carga del Dataset** - Desde Kaggle
4. **AnÃ¡lisis Exploratorio (EDA)** - ExploraciÃ³n de datos
5. **Preprocesamiento** - CodificaciÃ³n de variables
6. **DivisiÃ³n del Dataset** - Train/Test split (80/20)
7. **Modelo Base** - DecisionTree sin optimizar
8. **OptimizaciÃ³n de HiperparÃ¡metros** - GridSearchCV
9. **ValidaciÃ³n Cruzada** - EvaluaciÃ³n robusta
10. **EvaluaciÃ³n Detallada** - MÃºltiples mÃ©tricas
11. **Matriz de ConfusiÃ³n** - AnÃ¡lisis de errores
12. **VisualizaciÃ³n del Ãrbol** - GrÃ¡fico del modelo
13. **Importancia de Features** - Variables mÃ¡s relevantes
14. **ComparaciÃ³n de Modelos** - Base vs Optimizado
15. **Reglas del Ãrbol** - Interpretabilidad
16. **Resumen Final** - Resultados y archivos generados

## ğŸ“Š Resultados

El notebook generarÃ¡ automÃ¡ticamente:

### Modelos
- `decision_tree_model.pkl` - Modelo optimizado entrenado
- `label_encoders.pkl` - Codificadores de variables

### Visualizaciones
- `arbol_decision.png` - VisualizaciÃ³n del Ã¡rbol de decisiÃ³n
- `importancia_features.png` - GrÃ¡fico de importancia de variables
- `matriz_confusion.png` - Heatmap de la matriz de confusiÃ³n
- `comparacion_modelos.png` - ComparaciÃ³n Base vs Optimizado

### AnÃ¡lisis
- `arbol_reglas.txt` - Reglas del Ã¡rbol en formato texto

### ğŸ“ UbicaciÃ³n de los archivos

Todos los archivos se guardan en el **directorio raÃ­z del proyecto**, es decir:
```
\\wsl.localhost\Ubuntu\home\alex\proyects\Arbol-Decision\
```

Durante la ejecuciÃ³n, el notebook muestra la ruta completa donde se guardan los archivos.

### MÃ©tricas Esperadas
```
Accuracy:   ~0.95-1.00
Precision:  ~0.95-1.00
Recall:     ~0.95-1.00
F1-Score:   ~0.95-1.00
```

## ğŸ¤” Â¿Es necesaria la optimizaciÃ³n?

El notebook incluye optimizaciÃ³n de hiperparÃ¡metros con GridSearchCV. Sin embargo:

**Cuando el modelo base tiene >95% de accuracy:**
- La optimizaciÃ³n puede no mostrar mejoras significativas
- Esto es **normal y positivo**: indica que el dataset tiene patrones claros
- El modelo base ya captura bien la estructura de los datos

**El notebook detecta esto automÃ¡ticamente y:**
- âœ… Muestra un mensaje indicando que el rendimiento ya es excelente
- âœ… ContinÃºa con la optimizaciÃ³n para fines didÃ¡cticos
- âœ… Explica por quÃ© no hay mejora significativa en la comparaciÃ³n

**Beneficios de mantener la optimizaciÃ³n:**
- ğŸ“š Aprendizaje: Demuestra el proceso completo
- ğŸ” ValidaciÃ³n: Confirma que los parÃ¡metros por defecto son Ã³ptimos
- ğŸ›¡ï¸ PrevenciÃ³n de overfitting: Puede regularizar mejor el modelo

## ğŸ”§ HiperparÃ¡metros Optimizados

El GridSearchCV explora:
```python
param_grid = {
    'max_depth': [3, 5, 7, 10, 15, None],
    'min_samples_split': [2, 5, 10, 20],
    'min_samples_leaf': [1, 2, 4, 8],
    'criterion': ['gini', 'entropy']
}
```
**Total:** 192 combinaciones evaluadas con validaciÃ³n cruzada 5-fold

## ğŸ’¡ CÃ³mo usar el modelo guardado

```python
import joblib
import pandas as pd

# Cargar modelo y encoders
modelo = joblib.load('decision_tree_model.pkl')
encoders = joblib.load('label_encoders.pkl')

# Hacer predicciones con nuevos datos
# (primero codificar las variables categÃ³ricas con los encoders)
prediccion = modelo.predict(nuevos_datos)
probabilidades = modelo.predict_proba(nuevos_datos)
```

## ğŸ› ï¸ Dependencias Principales

- Python 3.8+
- pandas
- numpy
- scikit-learn
- matplotlib
- seaborn
- joblib
- kaggle

Ver `requirements.txt` para todas las dependencias y versiones.

## ğŸ“ CaracterÃ­sticas del Proyecto

- âœ… CÃ³digo profesional y documentado
- âœ… Explicaciones didÃ¡cticas en cada secciÃ³n
- âœ… Reproducible con random_state=42
- âœ… ValidaciÃ³n cruzada implementada
- âœ… MÃºltiples mÃ©tricas de evaluaciÃ³n
- âœ… Visualizaciones de calidad profesional
- âœ… Modelo interpretable y explicable
- âœ… Listo para GitHub y portafolio

## ğŸ“„ Licencia

Este proyecto estÃ¡ bajo licencia MIT. Ver `LICENSE` para mÃ¡s detalles.

---
**Ãšltima actualizaciÃ³n:** Febrero 2026  
**Estado:** âœ… Completado
